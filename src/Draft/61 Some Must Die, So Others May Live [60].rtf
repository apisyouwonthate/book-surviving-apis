{\rtf1\ansi\ansicpg1252\cocoartf1671
\stshfdbch0{\fonttbl\f0\fnil\fcharset0 Cochin;\f1\fnil\fcharset0 Cochin-Bold{\*\falt Cochin Bold};}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\stylesheet {\s0 Normal;}}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
{\info
{\author Phil Sturgeon}
{\creatim\yr2018\mo3\dy13\hr14\min45\sec29\timesinceref542641529}
{\revtim\yr2018\mo12\dy10\hr4\min48\sec49\timesinceref566106529}}\deftab720
\paperw12240\paperh15840\margl1800\margr1800\margt1440\margb1440\pard\pardeftab720\sl280\sa240\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
Any time spent waiting for a request that may never come is time that could be spent doing something useful. When the HTTP call is coming from a background worker in a backend application, that's a worker blocked from processing other jobs. Depending on how you have your background workers configured, the same threads might be shared for multiple jobs. If Job X is stuck for 30s waiting for this server that's failing, Job Y and Job Z will not be processed, or will be processed incredibly slowly.\
That same principle applies when the HTTP call is made within the web thread of a backend application. That's a web thread that could have been handling other requests! For example, you are building a backend application with an endpoint  `GET /external` which is making an HTTP calls some API. This call is usually blazing fast and has been forever, until suddenly squirrels chew threw some impotent cables, and that API is down a data centre. \
Your application is still working for now, and as usual other endpoint are still responding in 100ms. They will continue to respond so long as there are threads available in the various workers... but if the performance issues for the squirrel chewed API continue, every time a user hits `GET /something`, another thread becomes unavailable for that 30s.\'a0\
Let's do a bit of math. For each thread that gets stuck, given that thread is stuck for 30s, and most requests go through in 100ms, 
\f1\b that's 3000 potential requests not being handled
\f0\b0 . 3000 requests not being handled because of a single endpoint. There will continue to be fewer and fewer available workers, and given enough traffic to that payment endpoint, there might be zero available workers left to work on any the traffic to any other endpoints. Setting that timeout to 10s would result in the processing of 2000 more successful requests.\
As a general advice for backend developers it's always better to avoid making requests from the web thread. Use background jobs whenever possible.\
Making timeouts happen early is much more important than getting a fast failure. The most important benefit of failing fast is to give other resources the chance to work, and it gives users update into what's going on.\
Frontend developer might not have to worry about freeing up server resources, but they do have to worry about the UI freezing, or other requests being blocked due to browsers HTTP/1.1 connection limits! The concept is very similar for both frontend and backend, don't waste resources waiting for responses which probably aren't going to come.}